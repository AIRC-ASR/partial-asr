import torch
import json
import random
from transformers import WhisperProcessor, WhisperForConditionalGeneration
from datasets import load_dataset
from tqdm import tqdm
import numpy as np

processor = WhisperProcessor.from_pretrained("openai/whisper-small.en")
model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-small.en").to("cuda")

def get_remove_window(num_secs, dims_per_sec, size):
  start_pos = random.randint(0, size - (dims_per_sec * num_secs))
  end_pos = start_pos + (dims_per_sec * num_secs)
  return start_pos, end_pos

# Resource: https://huggingface.co/blog/how-to-generate
data = []
NUM_HYPOTHESES = 5

# 5%, 10%, 15%, 20%, 25%
PERCENTAGE_TO_REMOVE = 0.05
assert(PERCENTAGE_TO_REMOVE >= 0)

instruction = f"Perform error correction on the top{NUM_HYPOTHESES} outputs generated by an Automatic Speech Recognition (ASR) system. The ASR hypotheses, listed in order of their ASR posterior score, are as follows:"
dataset = load_dataset("librispeech_asr", "all", split="test.other", cache_dir="datasets")
NUM_DATA_POINTS = len(dataset) # 2939
for example in tqdm(dataset, total=NUM_DATA_POINTS):
  if len(data) == NUM_DATA_POINTS:
    break

  audio = example["audio"]
  num_secs = len(audio["array"]) / audio["sampling_rate"]
  if PERCENTAGE_TO_REMOVE > 0:
    num_secs_to_remove = PERCENTAGE_TO_REMOVE * num_secs
    start_secs = random.uniform(num_secs_to_remove, num_secs - num_secs_to_remove)
    end_secs = start_secs + num_secs_to_remove
    start_pos = int(start_secs * audio["sampling_rate"])
    end_pos = int(end_secs * audio["sampling_rate"])
    beginning_audio = audio["array"][:start_pos]
    ending_audio = audio["array"][end_pos:]
    partial_audio = np.concatenate((beginning_audio, ending_audio))
    instruction = f"Perform error correction on the top {NUM_HYPOTHESES} outputs generated by an Automatic Speech Recognition (ASR) system for the provided partial audio segment. The ASR hypotheses, listed in order of their ASR posterior score, are as follows:"
    
    # middle_10_seconds = audio["array"][10*dims_per_sec:20*dims_per_sec]
    # start_pos, end_pos = get_remove_window(NUM_SECS_TO_REMOVE, middle_10_seconds.shape[0]//10, middle_10_seconds.shape[0])
    # beginning_audio = middle_10_seconds[: start_pos]
    # ending_audio = middle_10_seconds[end_pos:]
  input_features = processor(partial_audio, sampling_rate=audio["sampling_rate"], return_tensors="pt").input_features

  output = processor.tokenizer._normalize(example["text"])
  id_ = example["id"]
  with torch.no_grad():
    beam_outputs = model.generate(
      input_features.to("cuda"),
      num_beams=NUM_HYPOTHESES,
      num_return_sequences=NUM_HYPOTHESES,
      max_new_tokens=256,
      early_stopping=True
    )

  input_text = ""
  for i, beam_output in enumerate(beam_outputs):
    hypothesis = f"<hypothesis{i + 1}>" + processor.tokenizer._normalize(processor.decode(beam_output, skip_special_tokens=True)) + f"</hypothesis{i + 1}>\n"
    print('C', hypothesis)
    input_text += hypothesis

  input_text += "\nPlease provide the corrected top1 ASR transcription of the given utterance only, do not add any explanations or other words."
  data_point = {
    "instruction": instruction,
    "input": input_text,
    "output": output,
  }
  data.append(data_point)

with open('/gpfs/u/home/NLUG/NLUGcbsm/scratch-shared/librispeech-data/-secs-removed/validation-clean.json', 'w') as json_file:
  json.dump(data, json_file)

"""
>>> instruction="Perform error correction on the top3 outputs generated by an Automatic Speech Recognition (ASR) system. The ASR hypotheses, listed in order of their ASR posterior score, are as follows:"
>>> input="<hypothesis1> he grasped the little passing </hypothesis1>\n<hypothesis2> he grasped the little parcel </hypothesis2>\n<hypothesis3> he grasped the little puzzle </hypothesis3>\n\nPlease provide the corrected top1 ASR transcription of the given utterance only, do not add any explanations or other words."
>>> prompt_input=f"{instruction}\n\n{input}"
>>> print(prompt_input)
Perform error correction on the top3 outputs generated by an Automatic Speech Recognition (ASR) system. The ASR hypotheses, listed in order of their ASR posterior score, are as follows:

<hypothesis1> he grasped the little passing </hypothesis1>
<hypothesis2> he grasped the little parcel </hypothesis2>
<hypothesis3> he grasped the little puzzle </hypothesis3>

Please provide the corrected top1 ASR transcription of the given utterance only, do not add any explanations or other words
"""
