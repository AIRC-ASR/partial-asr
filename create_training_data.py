import torch
import json
import random
from transformers import WhisperProcessor, WhisperForConditionalGeneration
from datasets import load_dataset
from tqdm import tqdm
import numpy as np

processor = WhisperProcessor.from_pretrained("openai/whisper-small.en")
model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-small.en").to("cuda")

def get_remove_window(num_secs, dims_per_sec, size):
  start_pos = random.randint(0, size - (dims_per_sec * num_secs))
  end_pos = start_pos + (dims_per_sec * num_secs)
  return start_pos, end_pos

# Resource: https://huggingface.co/blog/how-to-generate
data = []
NUM_HYPOTHESES = 5
NUM_SECS = 1
assert(NUM_SECS >= 0)
instruction = f"Perform error correction on the top{NUM_HYPOTHESES} outputs generated by an Automatic Speech Recognition (ASR) system. The ASR hypotheses, listed in order of their ASR posterior score, are as follows:"
dataset = load_dataset("librispeech_asr", "all", split="test.other", cache_dir="datasets")
NUM_DATA_POINTS = len(dataset) # 2939
for example in tqdm(dataset, total=NUM_DATA_POINTS):
  if len(data) == NUM_DATA_POINTS:
    break

  audio = example["audio"]
  dims_per_sec = audio["array"].shape[0] // 30
  if NUM_SECS == 0:
    input_features = processor(audio["array"], sampling_rate=audio["sampling_rate"], return_tensors="pt").input_features
  else:
    middle_10_seconds = audio["array"][10*dims_per_sec:20*dims_per_sec]
    start_pos, end_pos = get_remove_window(NUM_SECS, middle_10_seconds.shape[0]//10, middle_10_seconds.shape[0])
    beginning_audio = middle_10_seconds[: start_pos]
    ending_audio = middle_10_seconds[end_pos:]
    partial_audio = np.concatenate((beginning_audio, ending_audio))
    input_features = processor(partial_audio, sampling_rate=audio["sampling_rate"], return_tensors="pt").input_features

  output = processor.tokenizer._normalize(example["text"])
  id_ = example["id"]
  with torch.no_grad():
    beam_outputs = model.generate(
      input_features.to("cuda"),
      num_beams=NUM_HYPOTHESES,
      num_return_sequences=NUM_HYPOTHESES,
      max_new_tokens=256,
      early_stopping=True
    )

  input_text = ""
  for i, beam_output in enumerate(beam_outputs):
    hypothesis = f"<hypothesis{i + 1}>" + processor.tokenizer._normalize(processor.decode(beam_output, skip_special_tokens=True)) + f"</hypothesis{i + 1}>\n"
    input_text += hypothesis

  input_text += "\nPlease provide the corrected top1 ASR transcription of the given utterance only, do not add any explanations or other words."
  data_point = {
    "instruction": instruction,
    "input": input_text,
    "output": output,
  }
  data.append(data_point)

with open('/gpfs/u/home/NLUG/NLUGcbsm/scratch-shared/librispeech-data/original/train-clean-100.json', 'w') as json_file:
  json.dump(data, json_file)

"""
>>> instruction="Perform error correction on the top3 outputs generated by an Automatic Speech Recognition (ASR) system. The ASR hypotheses, listed in order of their ASR posterior score, are as follows:"
>>> input="<hypothesis1> he grasped the little passing </hypothesis1>\n<hypothesis2> he grasped the little parcel </hypothesis2>\n<hypothesis3> he grasped the little puzzle </hypothesis3>\n\nPlease provide the corrected top1 ASR transcription of the given utterance only, do not add any explanations or other words."
>>> prompt_input=f"{instruction}\n\n{input}"
>>> print(prompt_input)
Perform error correction on the top3 outputs generated by an Automatic Speech Recognition (ASR) system. The ASR hypotheses, listed in order of their ASR posterior score, are as follows:

<hypothesis1> he grasped the little passing </hypothesis1>
<hypothesis2> he grasped the little parcel </hypothesis2>
<hypothesis3> he grasped the little puzzle </hypothesis3>

Please provide the corrected top1 ASR transcription of the given utterance only, do not add any explanations or other words
"""
